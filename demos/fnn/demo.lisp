;;; -*- Mode:Lisp; Syntax:ANSI-Common-Lisp; Coding:utf-8; Package:AprilDemo.Fnn -*-
;;;; demo.lisp

(in-package #:april-demo.fnn)

"Implement a basic forward-feeding neural network. This demo network is trained and tested against the popular MNIST database of handwritten digits."

(defparameter *package-symbol* (intern (package-name *package*) "KEYWORD"))

;; import the display function from the April's array standard library
(april (with (:space fnn-demo-space))
       "display disp ← 'ARRAY-LIB-SPACE' ⎕XWF 'display' 'disp'")

#|
-- Function --
Normal Array Construction

This function generates arrays containing a normal distribution of randomly chosen floating point numbers.
|#

(april (with (:space fnn-demo-space))
       "
MakeNormalArray ← {
  U1 ← ?⍵⍴0
  U2 ← ?⍵⍴0
  s  ← (¯2×⍟U1)*÷2
  c  ← 2○2×○U2
  c×s
}
")

#|
∘○ To Verify ○∘
Normally Distributed Array Elements

* (verify-normal-array)

Evaluate this to see an array of normally-distributed floating point numbers. Optionally, pass a shape like #(2 3 4) to this function to receive an array of the corresponding shape.

You can optionally pass a set of dimensions to the function:

(verify-normal-array 2 3)

* (verify-normal-distrib)

Evaluate this to see a vector representing the distribution of values generated by MakeNormalArray. This function optionally takes a length argument to determine the length of the normal vector created:

(verify-normal-distrib 100)

* (verify-plot-normal-distrib)

Evaluate this to see a plot of the value distribution generated by MakeNormalArray. To use less elements and see a less normal distribution, try:

(verify-plot-normal-distrib :count 100)

Or try with larger counts like 10,000 to see a more normal distribution. You may pass a width argument to control the width of the plot: 

(verify-plot-normal-distrib :count 1000 :width 40)

This will produce a plot whose rows may be no longer than 40 characters.
|#

(defun verify-normal-array (&rest shape)
  "Generate an array of normally-distributed floating point numbers with an optional shape."
  (let ((shape (or shape '(10))))
    (april-c (with (:space fnn-demo-space)) "MakeNormalArray" (coerce shape 'vector))))

(defun verify-normal-distrib (&optional (count 1000))
  "Generate a vector of integers reflecting the distribution of floating point numbers in an array produced by MakeNormalArray."
  (april-c (with (:space fnn-demo-space))
           "{{{1-⍨≢⍵}⌸⍵,⍨⍳21}(2÷⍨⎕IO-⍨¯10+⍳21)⍸MakeNormalArray ⍵}"
           count))

(defun verify-plot-normal-distrib (&key (count 1000) (width 80))
  "Plot the distribution of numbers generated using MakeNormalArray."
  (april-c (with (:space fnn-demo-space))
           "{⍺{⎕←↑'⎕'⍴¨⍨⌊⍺×⍵÷⌈/⍵}{{1-⍨≢⍵}⌸⍵,⍨⍳21}(2÷⍨⎕IO-⍨¯10+⍳21)⍸MakeNormalArray ⍵}"
           count width)
  (format nil "Distribution of ~a random numbers plotted with width ~a." count width))

#|
-- Functions --
Network Construction

These functions are used to build neural networks.
|#

(april (with (:space fnn-demo-space))
       "
InitNetwork ← {
  ⍝ ⍵ is the shape of the network.
  ⍝ Returns a pair of weight matrices and bias vectors.
  (InitWeightMatrices ⍵) (InitBiasVectors ⍵)
}

InitBiasVectors ← {
  ⍝ ⍵ is the shape of the network.
  ⍝ Returns a vector of bias vectors.
  shape ← 1↓⍵
  (shape*0.5) ÷⍨ ⍪∘MakeNormalArray¨ shape
}

InitWeightMatrices ← {
  ⍝ ⍵ is the shape of the network.
  ⍝ Returns a vector of weight matrices.
  matrices ← MakeNormalArray¨ 2 ,⍨/⍵
  matrices ÷ 0.5*⍨2×/⍵
}
")

#|
∘○ To Verify ○∘
Neural Network Structure

* (verify-network-structure)

Evaluate this to see the printed structure of a random neural network. Optionally, you can set a shape for the network by passing a set of dimensions as the argument, like this:

(verify-network-structure 1 3 2)
|#

(defun verify-network-structure (&rest shape)
  "Display the structure of a neural network with an optionally specified shape."
  (let ((shape (or shape #(3 6 2))))
    (april-c (with (:space fnn-demo-space))
             "{⎕←display InitNetwork ⍵ ⋄ 'Printed network strucure with base shape ',(⍕⍵),'.'}"
             (coerce shape 'vector))))

#|
-- Function --
Forward Pass

This function derives output from a neural network based on input data and the weights assigned to the neurons.
|#

(april (with (:space fnn-demo-space))
       "
_ForwardPass ← {
  ⍝ ⍺⍺ is the activation function
  ⍝ ⍺ is the network
  ⍝ ⍵ is the network input
  (ws  bs) ← ⍺
  (_ _ xs) ← (⍺⍺ _F⍣(≢ws)) ws bs (⊂⍵)
  xs
}

_F ← {
  ⍝ ⍺⍺ is the activation function.
  ⍝ (ws bs xs) ← ⍵ are the components for the calculations.
  (ws bs xs) ← ⍵
  w   ← ⊃ ws
  b   ← ⊃ bs
  inp ← ⊃⌽xs
  x   ← ⍺⍺ b+w+.×inp
  (1↓ws) (1↓bs) (xs,⊂x)
}
")

#|
-- Function --
Output Activation

This function is used to postprocess the output of each layer of the neural network before it is passed to the next layer. It is assigned to a namespace containing its derivative as well as the "leaky parameter" determining the 
|#

(april (with (:space fnn-demo-space))
       "
LeakyReLU ← ⎕NS⍬

⎕CS LeakyReLU

leaky ← 0.1

F  ← {
  ⍝ ⍵ is the argument of the function.
  ⍵⌈leaky×⍵
}

DF ← {
  ⍝ ⍵ is the argument of the function.
  leaky⌈×⍵
}

⎕CS _
")

#|
∘○ To Verify ○∘
Activation and Neural Network Output

* (verify-activation-output)

Evaluate this to see the output of the LeakyReLU function. You can pass it a series of input values:

(verify-activation-output 10.0d0 -20.0d0 30.0d0)

* (verify-network-output)

Evaluate this to see the printed output of a random neural network. As with (verify-network-structure), you can optionally set a shape:

(verify-network-output 2 5 3)
|#

(defun verify-activation-output (&rest input)
  "Display the output of the LeakyReLU activation function called on an optionally specified series of numbers."
  (let ((input (or input #(1.0d0 -2.0d0 3.0d0 -4.0d0))))
    (april-c (with (:space fnn-demo-space)) "LeakyReLU.F" (coerce input 'vector))))

(defun verify-network-output (&rest shape)
  "Display the output of a forward pass through a neural network."
  (let ((shape (or shape #(3 6 2))))
    (april-c (with (:space fnn-demo-space))
             "{ 
⎕←display (InitNetwork ⍵) (LeakyReLU.F _ForwardPass) ⍪1↑⍨⊃⍵
'Printed output of neural network with shape ',(⍕⍵),'.'}"
             (coerce shape 'vector))))

#|
-- Function --
Loss Determination

This function is used to determine the quality of the network's output. It is assigned within a namespace alongside its derivative.
|#

(april (with (:space fnn-demo-space))
       "
MSELoss ← ⎕NS⍬

⎕CS MSELoss

F  ← {
  ⍝ Mean Squared Error loss function.
  ⍝ Find the errors, square them and average them.
  ⍝ ⍵ is the network output.
  ⍝ ⍺ is the correct target.
  sq ← 2*⍨⍵-⍺
  (≢sq) ÷⍨ +/,sq
}

DF ← {
  ⍝ Derivative of the MSELoss function.
  ⍝ ⍵ is the network output.
  ⍝ ⍺ is the correct target.
  (≢⍵)÷⍨2×⍵-⍺
}

⎕CS _
")

#|
∘○ To Verify ○∘
Loss Function and Its Derivative

* (verify-loss-convergence)

Evaluate this to see a vector of the output from the derivative loss function with a given input and the output of the algorithmically derived loss function given the same input and a given dx value. For example: 

(verify-loss-convergence :input 5 :dx 0.1)

* (verify-loss-convergence-series)

Evaluate this to see the same with a series of dx values, optionally with input:

(verify-loss-convergence-series :input 5 :series #(0.1d0 0.01d0 0.001d0))

* (verify-network-output-loss)

Evaluate this to see the loss value for a given input and output to a network. You can set a shape for the network as well as specifying the input and target values:

(verify-network-output-loss :shape #(3 6 2) :input #(2 0) :target #(0 1))
|#

(defun verify-loss-convergence (&key (input 3) (dx 0.1))
  "Show the derivative of the MSELoss function and the convergence of a value given its integral for an optionally specified input and dx value."
  (april-c (with (:space fnn-demo-space))
           "{
_D ← {⍺÷⍨(⍺⍺ ⍵+⍺)-⍺⍺ ⍵}
f  ← 4∘MSELoss.F
(4 MSELoss.DF ⍵),⍺ (f _D)¨⍵
}"
           input dx))

(defun verify-loss-convergence-series (&key (input 3) (series (april "0.1*⍳5")))
  "Evaluate (verify-loss-convergence) for a series of dx values to illustrate their convergence on the output of the derivative function."
  (verify-loss-convergence :input input :dx series))

(defun verify-network-output-loss (&key (shape #(2 5 3)) (input 0) (target 0))
  "Check the output of the MSELoss function called on the output of a forward pass with a neural network having optionally specified shape, input and target values."
  (april-c (with (:space fnn-demo-space))
           "{
inp    ← ⍪(⊃ ⍵)⍴⊃ ⍺
target ← ⍪(⊃⌽⍵)⍴⊃⌽⍺
net    ← InitNetwork ⍵
labels ← ⍪'Target' 'Output'

{⎕←labels,⊖⍉⍵,target ⋄ ⎕←'Loss: ',⍕target MSELoss.F ⍵} ⊃⌽net (LeakyReLU.F _ForwardPass) inp
'Target/output loss calculated.'
}"
           shape (vector input target)))

;; initialize dynamic function assignments for use within _Train
;; TODO: this can be better architected
(april (with (:space fnn-demo-space))
       "
 fAct  ← LeakyReLU.F
dfAct  ← LeakyReLU.DF
 fLoss ←   MSELoss.F
dfLoss ←   MSELoss.DF
")

#|
-- Function --
Network Training

This function performs a training iteration on a neural network.
|#

(april (with (:space fnn-demo-space))
       "
_Train ← {
  (Ws bs) ← ⍶
  xs      ← ⍶ (fAct _ForwardPass) ⍵
  dx      ← ⍺ dfLoss ⊃⌽xs

  ⍝ TODO: ⊢⊢ below shouldn't be needed
  Ws bs-0.001×↓⌽⍉↑⊢⊢{
    (W b x) ← ⍵⊃¨Ws bs xs
    db      ← dx×dfAct b+W+.×x
    dx     ⊢← db+.×⍨⍉W
    (db+.×⍉x) db
  }¨⊢⊣⌽⍳≢Ws
}
")

#|
∘○ To Verify ○∘
Trained Network States

* (verify-training-output)

Evaluate this to either 1. initialize a neural network if none is stored or 2. perform an iteration of training upon the stored neural network.

* (verify-training-output-restart)

Evaluate this to start again with a fresh neural network.

As with (verify-loss-applied), (verify-training-output) can take 3 arguments specifying the shape of the network, its input and its target:

(verify-training-output :shape #(3 6 2) :input #(0 2) :target 1)

The input and target values will be reshaped into vectors matching the first and last dimensions of the network, respectively. Changing the shape, input or target values when a network exists will cause the network to be rebuilt with those values applying.
|#

(let ((net-state) (net-shape) (net-input) (net-target)
      (derived-input) (derived-target) (iteration 0))
  (defun verify-training-output-restart ()
    "Clear the network state of the training output test function."
    (setf net-state nil))
  (defun verify-training-output (&key (shape #(2 5 3)) (input 0) (target 0))
    "Get the output of a training iteration upon a neural network with an optionally specified shape, input and target."
    (unless (equalp shape net-shape)
      (setf net-shape shape
            net-state nil))
    (unless (equalp input net-input)
      (setf net-input input
            derived-input (april-c  "{⍪⍺⍴⍨⊃ ⍵}" net-shape input)
            net-state nil))
    (unless (equalp target net-target)
      (setf net-target target
            derived-target (april-c "{⍪⍺⍴⍨⊃⌽⍵}" net-shape target)
            net-state nil))
    (if net-state
        (setf net-state (april (with (:space fnn-demo-space)
                                     (:state :in ((net net-state) (target derived-target)
                                                  (inp derived-input))))
                               "target (net _Train) inp")
              iteration (1+ iteration))
        (setf net-state (april-c (with (:space fnn-demo-space)) "InitNetwork" net-shape)
              iteration 0))
    (april-c (with (:space fnn-demo-space))
             "{⎕←display ⍵ ⋄ 0=⍺ : 'Network initialized!' ⋄ 'Training iteration: ',⍕⍺}"
             net-state iteration)))

;; ;; TODO: this causes a bug above, returns nil - why?
;; (april-c (with (:space fnn-demo-space))
;;          "{ (inp target) ← ⍺ ⋄ target (⍵ _Train) inp }"
;;          net-state (vector derived-input derived-target))

#|
== MNIST Digit Image Recognition Test Case ==
The forward-feeding neural network model is to be tested against the MNIST database of handwritten digits. This dataset is made up of four .idx files which are currently available in GZipped format at these URLs:

https://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
https://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz
https://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz
https://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz

The files must be downloaded and unzipped inside the input/ directory located inside the same directory as this source file.

The following functions implement tools for importing the MNIST data into arrays that may be processed using April and the neural network modeled above.
|#

;; binary format for .idx files
(defbinary idx-file (:byte-order :big-endian)
  (empty 0 :type 16)
  (type 0 :type 8)
  (rank 0 :type 8)
  (dimensions #() :type (simple-array (unsigned-byte 32) (rank)))
  (data #() :type (eval (case type (#x08 `(simple-array (unsigned-byte 8) (,(reduce #'* dimensions))))
                              (#x09 `(simple-array (signed-byte 8) (,(reduce #'* dimensions))))
                              (#x0b `(simple-array (signed-byte 16) (,(reduce #'* dimensions))))
                              (#x0c `(simple-array (signed-byte 32) (,(reduce #'* dimensions))))
                              (#x0d `(simple-array single-float (,(reduce #'* dimensions))))
                              (#x0e `(simple-array double-float (,(reduce #'* dimensions))))))))

(defun idx-file-to-array (file-path)
  "Load the contents of an .idx file into an array."
  (with-open-binary-file (in-raw file-path :direction :input)
    (with-wrapped-in-bit-stream (in in-raw :byte-order :big-endian)
      (let ((idx-input (read-binary 'idx-file in)))
        (if (= 1 (slot-value idx-input 'rank))
            (slot-value idx-input 'data)
            (make-array (loop :for d :across (slot-value idx-input 'dimensions) :collect d)
                        :element-type (array-element-type (slot-value idx-input 'data))
                        :displaced-to (slot-value idx-input 'data)))))))

(let ((training-data) (training-labels) (test-data) (test-labels))
  (defun load-idx-files ()
    "Load data from .idx files in the input/ directory into four variables."
    (setf training-data (idx-file-to-array (asdf:system-relative-pathname
                                            *package-symbol* "input/train-images.idx3-ubyte"))
          training-labels (idx-file-to-array (asdf:system-relative-pathname
                                              *package-symbol* "input/train-labels.idx1-ubyte"))
          test-data (idx-file-to-array (asdf:system-relative-pathname
                                        *package-symbol* "input/t10k-images.idx3-ubyte"))
          test-labels (idx-file-to-array (asdf:system-relative-pathname
                                          *package-symbol* "input/t10k-labels.idx1-ubyte")))
    "MNIST digit image data loaded.")
  ;; these functions fetch the input data
  (defun get-training-data () training-data)
  (defun get-training-labels () training-labels)
  (defun get-test-data () test-data)
  (defun get-test-labels () test-labels))

#|
○∘ To Demonstrate ∘○

* (load-digit-data)

Evaluate this, followed by...

* (build-digit-network)

...to load the MNIST training data and build a neural network. Then:

* (train-digit-network)

Evaluate this to train the network. Optionally, a count argument may be passed if you wish to train the network on a limited subset of the MNIST training data rather than training on all 60,000 images:

(train-digit-network 2000)

The functions (get-net-state) (get-data-segment) and (set-data-segment) are utility functions which may be useful in analyzing the data passing through the network.

The (build-digit-network) function can optionally be passed a set of intermediate dimensions. For example:

(build-digit-network 12 18)

Will yield a training network with shape 728 12 18 10. The default shape is 728 16 16 10, which has been found to produce good results with the MNIST digit set, but you can use dimensional inputs to experiment with other structures.

Once the network has been trained, it's ready to be tested against the set of testing images. To do this:

* (test-digit-network)

Evaluate this to test the network against the set of MNIST test images. You can pass a count argument like this:

(test-digit-network 400)

To test against only the first N images in the set. In the above case, only the first 400 images are tested against.
|#

(let ((net-shape) (net-state) (image-size 0) (training-data) (training-labels) (test-data) (test-labels)
      ;; tabled vectors representing the target states for the 10 digits
      (segment-dims) (tdata-segment) (tsdata-segment) (ovec-length) (output-holder) (oh-segment)
      (target-arrays (april "(⊂3⎕DT 10 1↑1)⊖¨⍨-⎕IO-⍨⍳10")))
  (defun load-digit-data ()
    "Load the training dataset of handwritten digit images from MNIST."
    (unless training-data
      (unless (get-training-data)
        (format t "Loading MNIST training and test images...~%")
        (load-idx-files))
      (setf training-data (get-training-data)
            training-labels (get-training-labels)
            test-data (get-test-data)
            test-labels (get-test-labels)
            image-size (reduce #'* (rest (array-dimensions training-data)))
            segment-dims (list image-size 1)
            ;; the digit image frames are raveled into 784-element tabled vectors for input
            tdata-segment (make-array segment-dims
                                      :element-type (array-element-type training-data)
                                      :displaced-to training-data :displaced-index-offset 0)
            tsdata-segment (make-array segment-dims
                                       :element-type (array-element-type test-data)
                                       :displaced-to test-data :displaced-index-offset 0)))
    (april-c "{'Loaded ',(⍕≢⍵),' MNIST training images and ',(⍕≢⍺),' test-images with labels.'}" training-labels test-labels))

  (defun build-digit-network (&rest intermediate-shape)
    "Generate a neural network with an optionally specified intermediate state (not determined by the input or output shapes)."
    (let ((intermediate-shape (or intermediate-shape #(16 16))))
      (setf net-shape (april-c "{⍵,⍺,10}" image-size (coerce intermediate-shape 'vector))
            net-state (april-c (with (:space fnn-demo-space)) "InitNetwork" net-shape))
      (april-c "{'Built MNIST digit recognition network with shape ',(⍕⍵),'.'}" net-shape)))

  (defun get-net-state ()
    "Retrieve the state of the neural network."
    net-state)

  (defun set-net-state (data)
    "Set the state of the neural network."
    (setf net-state data))
  
  (defun get-data-segment ()
    "Retrive the currently designated digit image in the form of a tabled integer vector."
    tdata-segment)

  (defun set-data-segment (index)
    "Set the designated digit image."
    (adjust-array tdata-segment segment-dims
                  :displaced-to training-data :displaced-index-offset (* index image-size)))
  
  (defun get-tsdata-segment ()
    "Retrive the currently designated digit image in the form of a tabled integer vector."
    tsdata-segment)

  (defun set-tsdata-segment (index)
    "Set the designated digit image."
    (adjust-array tsdata-segment segment-dims
                  :displaced-to test-data :displaced-index-offset (* index image-size)))

  (defun build-output-holder (length)
    (setf ovec-length (aref net-shape (1- (length net-shape)))
          output-holder (make-array (list length ovec-length) :element-type 'double-float)
          oh-segment (make-array ovec-length :element-type 'double-float :displaced-to output-holder)))

  (defun get-output-holder ()
   output-holder)
  
  (defun set-oh-segment (index)
    (adjust-array oh-segment ovec-length
                  :element-type 'double-float :displaced-to output-holder
                  :displaced-index-offset (* index ovec-length)))

  (defun get-oh-segment ()
    oh-segment)
  
  (defun verify-mnist-image-pass ()
    "See the output of a forward pass with the currently designated digit within the MNIST training image set."
    (build-digit-network)
    (april-c (with (:space fnn-demo-space))
             "{⎕←display 1↓⍵ (LeakyReLU.F _ForwardPass) ⍺ ⋄ 'Printed calculated bias vectors.'}"
             net-state (get-data-segment)))

  (defun train-digit-network (&optional count)
    "Train the created neural net on the set of MNIST images, either up to an optionally specified count or processing all 60,000 images."
    (let ((notice-interval 200)
          (count (or (and count (min count (length training-labels)))
                     (length training-labels))))
      (format t "Training network on ~a images.~%" count)
      (let ((progress-bar-advancer (april-print-progress-bar :count count)))
        (dotimes (index count)
          (set-data-segment index)
          (set-net-state (april (with (:space fnn-demo-space)
                                      (:state :in ((net (get-net-state))
                                                   (target (aref target-arrays (aref training-labels index)))
                                                   (inp (get-data-segment)))))
                                "target (net _Train) inp"))
          (funcall progress-bar-advancer))
        (format nil "Completed ~a training iterations." count))))

  (defun test-digit-network (&optional count)
    "Test the trained neural network against the database of MNIST test images."
    (let ((notice-interval 200)
          (correct-guesses 0)
          (count (or (and count (min count (length test-labels)))
                     (length test-labels))))
      (format t "Testing network on ~a images.~%" count)
      (build-output-holder count)
      (let ((output) (progress-bar-advancer (april-print-progress-bar :count count)))
        (dotimes (index count)
          (set-tsdata-segment index)
          (set-oh-segment index)
          (setf output (april-c (with (:space fnn-demo-space))
                                "{,⊃⌽⍵ (LeakyReLU.F _ForwardPass) ⍺}"
                                net-state (get-tsdata-segment)))
          (loop :for o :across output :for i :from 0 :do (setf (aref oh-segment i) o))
          (funcall progress-bar-advancer))
        (format nil "Completed ~a neural network tests." count)))))

(defun analyze-network-output (&optional count)
  "Print a chart of values reflecting the performance of the completed network test."
  (april-c (with (:space fnn-demo-space)
                 (:state :in ((count (or count 0)))))
           "{
  c       ← $[count;count;≢⍵]
  ⎕IO     ← 0
  labels  ← 'Number' 'Hits' 'Misses' 'Total' 'Hit%'
  labels ,← 'Avg. Hit Str.' 'Avg. Miss Str.' 'Avg. Missed Str.'
  labels ,← 'Avg. Divergence' 'Avg. Hit Div.' 'Avg. Miss Div.'

  format  ← {
    table ← ⍵⍪(≢⍉⍵)↑(⊂'Total'),(+⌿⍵[;1+⍳3]),(+⌿÷≢)⍵[;4+⍳4-⍨≢⍉⍵]
    ⍝ render the averaged numbers in columns so that the ¯ signs line up
    labels⍪(3∘⍕¨table[;⍳5]),⍉↑↓¨8∘⍕¨1⊂table[;5+⍳5-⍨≢⍉⍵]
  }

  ⎕←0 disp format↑{
            ⍝ ⎕IO ← 0 TODO: doesn't work here
    (i r) ← ⍵
    ind   ← ⍒¨r
          ⍝ ranking vector of match elements by intensity
    mat   ← i⌷¨r
          ⍝ intensities of matching elements
    ord   ← r{⍺[⍵]}¨ind
          ⍝ elements ranked by intensity
    hits  ← i=⊃¨ind
          ⍝ binary vector of correct guesses for number
    htot  ← +/hits
          ⍝ total number of hits
    mtot  ← htot-⍨≢ind
          ⍝ total number of misses
    hpct  ← 100×htot÷1.0×≢r
          ⍝ printed percentage of hits
    hstr  ← $[0=htot;⍬;(+/÷≢)mat× hits]
          ⍝ avg. intensity of hits
    mstr  ← $[0=mtot;⍬;(+/÷≢)mat×~hits]
          ⍝ avg. intensity of correct element match on a miss
    mhstr ← $[0=mtot;⍬;(+/÷≢)(⊃¨ord)×~hits]
          ⍝ avg. intensity of matching elements on misses
    divr  ← {+/1↓⍵}¨ord
          ⍝ total divergence (sum of incorrect element intensities) for each try
    adivr ← (+/÷≢)divr
          ⍝ average of all divergence values
    hdivr ← $[0=htot;⍬;(+/÷≢)divr/⍨ hits]
          ⍝ avg. divergence of hits
    mdivr ← $[0=mtot;⍬;(+/÷≢)divr/⍨~hits]
          ⍝ avg. divergence of misses

    i htot mtot (≢r) hpct hstr mstr mhstr adivr hdivr mdivr
  }¨{⍵[⍋⊃¨⍵]}(c↑⍺){⊂⍺ ⍵}⌸↓c↑⍵
  'Analysis complete.'
}"
           (get-output-holder) (get-test-labels)))
